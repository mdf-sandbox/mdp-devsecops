name: reusable-workflow-deploy-ing

on:
  workflow_call:
    inputs:
      environment:
        type: string
        description: Target environment
        required: true
      repository:
        type: string
        description: Repository name
        required: true
      ref:
        type: string
        description: Branch name
        required: true
      baseline_no:
        type: string
        description: Deployment Baseline Number
        required: true
      post_deployment_script:
        type: string
        description: Post-deployment Scripts
        required: true
      run_id:
        type: string
        description: Databricks Run ID
        required: true

  # Allows you to run this workflow manually from the Action tab
  workflow_dispatch:
    inputs:
      environment:
        type: choice
        description: Target environment
        options:
         - uat
         - prod
      repository:
        type: string
        description: Repository name
        required: true
      ref:
        type: string
        description: Release tag
        required: true
      baseline_no:
        type: string
        description: Deployment Baseline Number
        required: true
      post_deployment_script:
        type: string
        description: Post-deployment Scripts
        required: true
      run_id:
        type: string
        description: Databricks Run ID
        required: true

# Use the Bash shell as default settings for all jobs in the workflow
defaults:
  run:
    shell: bash

jobs:
  check-approval-gate:
    name: Check Approval Gate
    runs-on: ubuntu-20.04
    outputs:
      pre_approve_status: ${{ steps.op1.outputs.pre_approve_status }}
      post_approve_status: ${{ steps.op2.outputs.post_approve_status }}

    steps:
      - name: Set default approval status
        if: always()
        id: op1
        run: |
          echo "pre_approve_status=approved" >> $GITHUB_OUTPUT

      - name: Checkout main branch of DevOps repository
        if: ${{ inputs.run_id != '' }}
        uses: actions/checkout@v4
        with:
          repository: ${{ vars.DEVSECOPS_REPOSITORY_VAR }}
          ref: main
          fetch-depth: 0

      - name: Set environment variables
        if: ${{ inputs.run_id != '' }}
        env:
          REPOSITORY_VAR: ${{ inputs.repository }}
        run: |
          # echo "APPROVAL_GATE_ENVIRONMENT=${{ inputs.environment == 'uat' && 'sit' || 'uat' }}" >> $GITHUB_ENV
          # echo "APPROVAL_GATE_PATH=${{ inputs.environment == 'uat' && '/Shared/MDF/$REPOSITORY_VAR/sit' || '/Shared/MDF/$REPOSITORY_VAR/uat' }}" >> $GITHUB_ENV
          echo "APPROVAL_GATE_ENVIRONMENT=dev" >> $GITHUB_ENV
          echo "APPROVAL_GATE_PATH=/test/mdp/unit/ingestion_area1/" >> $GITHUB_ENV #HARDCODE FOR TEST

      - name: Load environment variables from ${{ env.APPROVAL_GATE_ENVIRONMENT }} dotenv file
        if: ${{ inputs.run_id != '' }}
        run: |
          cat ./dotenv/${{ env.APPROVAL_GATE_ENVIRONMENT }}.env >> $GITHUB_ENV

      - name: Install pip and etc
        if: ${{ inputs.run_id != '' }}
        run: |
          pip install --upgrade pip
          pip install jq
          pip install yq

      - name: Install Databricks CLI
        if: ${{ inputs.run_id != '' }}
        run: |
          curl -fsSL https://raw.githubusercontent.com/databricks/setup-cli/main/install.sh | sh

      - name: Connect to Databricks with Frmwk profiles
        if: ${{ inputs.run_id != '' }}
        run: |
          echo ${{ secrets.AZURE_DATABRICKS_PAT }} | \
            databricks configure --profile ar-frmwk --host ${{ env.DATABRICKS_HOST }} --token #TODO: ${{ vars.DATABRICKS_PROFILE }}

      - name: Get metadata from Databricks workflow Run ID
        if: ${{ inputs.run_id != '' }}
        run: |
          databricks --profile ar-frmwk jobs get-run ${{ inputs.run_id }} | jq '{result_state: .state.result_state, notebook_path: .job_parameters[] | select(.name=="notebook_path") | .value, run_page_url: .run_page_url}' > run_metadata.json #TODO: ${{ vars.DATABRICKS_PROFILE }}
          cat run_metadata.json

      - name: Set environment variables from metadata
        if: ${{ inputs.run_id != '' }}
        run: |
          echo "RUN_RESULT_STATE=$(jq -r '.result_state' run_metadata.json)" >> $GITHUB_ENV
          echo "RUN_NOTEBOOK_PATH=$(jq -r '.notebook_path' run_metadata.json)" >> $GITHUB_ENV
          echo "RUN_PAGE_URL=$(jq -r '.run_page_url' run_metadata.json)" >> $GITHUB_ENV

      - name: Pending Approval
        id: op2
        if: ${{ (inputs.run_id != '') && ((!startsWith(env.RUN_NOTEBOOK_PATH, env.APPROVAL_GATE_PATH)) || (env.RUN_RESULT_STATE != 'SUCCESS')) }}
        run: |
          echo "::error::Please check the result of workflow run id '${{ inputs.run_id }}' from this url '${{ env.RUN_PAGE_URL }}'"
          echo "post_approve_status=pending" >> $GITHUB_OUTPUT
          exit 1

  deploy-databricks-bundle:
    name: Deploy Databricks Bundle to ${{ inputs.environment }} Environment
    runs-on: ubuntu-20.04
    needs: [check-approval-gate]
    outputs:
      work_item_id: ${{ steps.op1.outputs.work_item_id }}

    steps:
      - name: Checkout main branch of DevSecOps repository
        uses: actions/checkout@v4
        with:
          repository: ${{ vars.DEVSECOPS_REPOSITORY_VAR }}
          ref: main
          fetch-depth: 0

      - name: Load environment variables from ${{ inputs.environment }} dotenv file
        run: |
          cat ./dotenv/${{ inputs.environment }}.env >> $GITHUB_ENV

      - name: Checkout ${{ inputs.ref }} of ${{ inputs.repository }} repository
        uses: actions/checkout@v4
        with:
          repository: ${{ inputs.repository }}
          ref: ${{ inputs.ref }}
          fetch-depth: 0
          token: ${{ secrets.GHE_DEVOPS_TOKEN }} #TODO ${{ secrets.GITHUB_MDP_DEVSECOPS_TOKEN }}

      - name: Load environment variables from cicd env file
        run: |
          cat ./deployment/service/azure_devops/azure_devops_boards.env >> $GITHUB_ENV

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ vars.PYTHON_VERSION_VAR }}

      - name: Install Poetry
        uses: snok/install-poetry@v1
        with:
          version: ${{ vars.POETRY_VERSION_VAR }}

      - name: Install pip and etc
        run: |
          pip install --upgrade pip
          pip install jq
          pip install yq

      - name: Install Databricks CLI
        run: |
          curl -fsSL https://raw.githubusercontent.com/databricks/setup-cli/main/install.sh | sh

      - name: Set environment variables
        run: |
          echo "DEFAULT_WORKFLOW_NAME=$(echo ${{ inputs.repository }} | awk -F'/' '{print $2}')" >> $GITHUB_ENV
          echo "REPOSITORY=${{ inputs.repository }}" >> $GITHUB_ENV
          echo "APPROVAL_GATE_PATH=/Shared/MDF/${{ inputs.repository }}/${{ inputs.environment }}" >> $GITHUB_ENV
          echo "SCRIPTS_PATH=/Shared/MDF/${{ inputs.repository }}/scripts" >> $GITHUB_ENV
          echo "PACKAGE_NAME=$(echo ${{ inputs.repository }} | awk -F'/' '{print $2}')" >> $GITHUB_ENV
          echo "CURRENT_VERSION=$(poetry version --dry-run -s)" >> $GITHUB_ENV
          echo "WORKSPACE_PATH=$(yq '.file_location_config' ./deployment/service/databricks/config.yml | jq -c '.workspace | to_entries')" >> $GITHUB_ENV

      - name: Override WORKSPACE_PATH variable
        run: |
          case ${{ inputs.environment }} in
            "dev")
              echo "WORKSPACE_PATH=$(echo '${{ env.WORKSPACE_PATH }}' |  jq -c ['.[] | select(.key | contains("sit_test") or contains("uat_test") | not )'])" >> $GITHUB_ENV
            ;;
            "sit")
              echo "WORKSPACE_PATH=$(echo '${{ env.WORKSPACE_PATH }}' |  jq -c ['.[] | select(.key | contains("unit_test") or contains("uat_test") | not )'])" >> $GITHUB_ENV
            ;;
            "uat")
              echo "WORKSPACE_PATH=$(echo '${{ env.WORKSPACE_PATH }}' |  jq -c ['.[] | select(.key | contains("unit_test") or contains("sit_test") | not )'])" >> $GITHUB_ENV
            ;;
            "prod")
              echo "WORKSPACE_PATH=$(echo '${{ env.WORKSPACE_PATH }}' |  jq -c ['.[] | select(.key | contains("_test") | not )'])" >> $GITHUB_ENV
            ;;
          esac

      - name: Connect to Databricks with Frmwk profiles
        run: |
          echo ${{ secrets.AZURE_DATABRICKS_PAT }} | \
            databricks configure --profile ar-frmwk --host ${{ env.DATABRICKS_HOST }} --token #TODO: ${{ vars.DATABRICKS_PROFILE }}

      - name: Delete files from the destination
        run: |
          for path in $(echo '${{ env.WORKSPACE_PATH }}' | jq -c '.[]'); do
              SOURCE_PATH=$(echo "$path" | jq -r '.key')
              DEST_PATH=$(echo "$path" | jq -r '.value')
              echo "Creating directory in workspace path ${DEST_PATH}..."
              databricks --profile ar-frmwk workspace mkdirs ${DEST_PATH} #TODO: ${{ vars.DATABRICKS_PROFILE }}
              echo "Listing files in workspace path ${DEST_PATH}..."
              databricks --profile ar-frmwk workspace list ${DEST_PATH} #TODO: ${{ vars.DATABRICKS_PROFILE }}
              if [[ ${SOURCE_PATH} != *"_test" ]]; then
                echo "Deleting files in workspace path ${DEST_PATH}..."
                databricks --profile ar-frmwk workspace delete ${DEST_PATH} --recursive #TODO: ${{ vars.DATABRICKS_PROFILE }}
              fi
          done

      - name: Validate the bundle configuration files
        run: |
          databricks --profile ar-frmwk bundle validate #TODO: ${{ vars.DATABRICKS_PROFILE }}

      - name: Deploy the bundle
        run: |
          databricks --profile ar-frmwk bundle deploy #TODO: ${{ vars.DATABRICKS_PROFILE }}

      - name: Set job outputs
        id: op1
        run: |
          echo "work_item_id=$(echo ${{ env.WORK_ITEM_ID }})" >> $GITHUB_OUTPUT

  deploy-files-to-volumes:
    name:  Deploy Files to Databricks Volumes
    runs-on: ubuntu-20.04
    needs: [check-approval-gate]

    steps:

      - name: Checkout main branch of DevSecOps repository
        uses: actions/checkout@v4
        with:
          repository: ${{ vars.DEVSECOPS_REPOSITORY_VAR }}
          ref: main
          fetch-depth: 0

      - name: Load environment variables from ${{ inputs.environment }} dotenv file
        run: |
          cat ./dotenv/${{ inputs.environment }}.env >> $GITHUB_ENV

      - name: Checkout ${{ inputs.ref }} of ${{ inputs.repository }} repository
        uses: actions/checkout@v4
        with:
          repository: ${{ inputs.repository }}
          ref: ${{ inputs.ref }}
          fetch-depth: 0
          token: ${{ secrets.GHE_DEVOPS_TOKEN }} #TODO ${{ secrets.GITHUB_MDP_DEVSECOPS_TOKEN }}

      - name: Install pip and etc
        run: |
          pip install --upgrade pip
          pip install jq
          pip install yq

      - name: Install AzCopy
        run: |
          wget -O azcopy_v10.tar.gz https://aka.ms/downloadazcopy-v10-linux && tar -xf azcopy_v10.tar.gz --strip-components=1

      - name: Set environment variables
        run: |
          echo "DEFAULT_WORKFLOW_NAME=$(echo ${{ inputs.repository }} | awk -F'/' '{print $2}')" >> $GITHUB_ENV
          echo "REPOSITORY=${{ inputs.repository }}" >> $GITHUB_ENV
          echo "APPROVAL_GATE_PATH=/Shared/MDF/${{ inputs.repository }}/${{ inputs.environment }}" >> $GITHUB_ENV
          echo "SCRIPTS_PATH=/Shared/MDF/${{ inputs.repository }}/scripts" >> $GITHUB_ENV
          echo "PACKAGE_NAME=$(echo ${{ inputs.repository }} | awk -F'/' '{print $2}')" >> $GITHUB_ENV
          echo "CURRENT_VERSION=$(poetry version --dry-run -s)" >> $GITHUB_ENV
          echo "ADLS_ARTIFACT_PATH=$(yq '.file_location_config' ./deployment/service/databricks/config.yml | jq -c '.adls_artifact | to_entries')" >> $GITHUB_ENV
          echo "AZCOPY_AUTO_LOGIN_TYPE=SPN" >> $GITHUB_ENV
          echo "AZCOPY_SPA_APPLICATION_ID=64443cb0-2542-4e10-90e2-f04295538d58" >> $GITHUB_ENV
          echo "AZCOPY_SPA_CLIENT_SECRET=${{ secrets.AZCOPY_SPA_CLIENT_SECRET }}" >> $GITHUB_ENV
          echo "AZCOPY_TENANT_ID=2aa3892b-2638-4281-a7e3-9623e880e79e" >> $GITHUB_ENV

      - name: Deploy Files to Databricks Volumes
        run: |
          for path in $(echo '${{ env.ADLS_ARTIFACT_PATH }}' | jq -c '.[]'); do
              SOURCE_PATH=$(echo "$path" | jq -r '.key')
              DEST_PATH=$(echo "$path" | jq -r '.value')
              echo "Deploying files to artifact path ${DEST_PATH}..."
              azcopy sync ".${DEST_PATH}" "https://pocadlsmdf.dfs.core.windows.net/artifact/mdf/ingestion/test_deployment${DEST_PATH}" --exclude-pattern=.gitkeep --delete-destination=true
              # azcopy sync ".${DEST_PATH}" "https://adlsmdfseatestfw001.dfs.core.windows.net/artifact${DEST_PATH}" --exclude-pattern=.gitkeep --delete-destination=true
          done

  execute-post-deployment-script:
    name: Execute Post-deployment Script
    runs-on: ubuntu-20.04
    needs: [deploy-databricks-bundle, deploy-files-to-volumes]
    # needs: [deploy-databricks-bundle] #TODO: REMOVE
    strategy:
      # fail-fast: true
      max-parallel: 1 #To define the maximum number of concurrent jobs
      matrix:
        post_deployment_script: ${{ fromJSON(inputs.post_deployment_script) }}

    steps:
      - name: Checkout main branch of DevSecOps repository
        if: ${{ inputs.post_deployment_script != '["skip"]' }}
        uses: actions/checkout@v4
        with:
          repository: ${{ vars.DEVSECOPS_REPOSITORY_VAR }}
          ref: main
          fetch-depth: 0

      - name: Load environment variables from ${{ inputs.environment }} dotenv file
        if: ${{ inputs.post_deployment_script != '["skip"]' }}
        run: |
          cat ./dotenv/${{ inputs.environment }}.env >> $GITHUB_ENV

      - name: Checkout ${{ inputs.ref }} of ${{ inputs.repository }} repository
        if: ${{ inputs.post_deployment_script != '["skip"]' }}
        uses: actions/checkout@v4
        with:
          repository: ${{ inputs.repository }}
          ref: ${{ inputs.ref }}
          fetch-depth: 0
          token: ${{ secrets.GHE_DEVOPS_TOKEN }} #TODO ${{ secrets.GITHUB_MDP_DEVSECOPS_TOKEN }}

      - name: Install pip and etc
        if: ${{ inputs.post_deployment_script != '["skip"]' }}
        run: |
          pip install --upgrade pip
          pip install jq
          pip install yq

      - name: Set environment variables
        if: ${{ inputs.post_deployment_script != '["skip"]' }}
        run: |
          echo "POST_DEPLOYMENT_SCRIPT_PATH=$(yq '.file_location_config' ./deployment/service/databricks/config.yml | jq -c '.workspace | to_entries' | jq -r '.[] | select(.key=="post_deployment_script") | .value')" >> $GITHUB_ENV

      - name: Trigger databricks notebook
        id: databricks-run
        if: ${{ inputs.post_deployment_script != '["skip"]' }}
        uses: databricks/run-notebook@v0
        with:
          databricks-host: ${{ env.DATABRICKS_HOST }}
          databricks-token: ${{ secrets.AZURE_DATABRICKS_PAT }}
          run-name: "execute-post-deployment-script"
          workspace-notebook-path: "${{ env.POST_DEPLOYMENT_SCRIPT_PATH }}${{ inputs.baseline_no }}/${{ matrix.post_deployment_script }}"
          # existing-cluster-id: "0921-080330-m15ze66k" #dp-batch-processing
          existing-cluster-id: "1002-080329-vfiifjp9" #dp_fw_developing
          notebook-params-json: >
            [
              {
                "key": "environment",
                "value": "${{ inputs.environment }}"
              }
            ]
          access-control-list-json: >
            [
              {
                "user_name": "a.hongtrakulchai@accenture.com",
                "permission_level": "IS_OWNER"
              }
            ]
          # timeout-seconds: 900 #15 Minutes

      - name: Check Run Output
        if: ${{ inputs.post_deployment_script != '["skip"]' }}
        run: |
          echo ${{ steps.databricks-run.outputs.notebook-output }}

  update-work-item:
    name: Update work item on Azure Boards
    runs-on: ubuntu-20.04
    needs: [deploy-databricks-bundle, deploy-files-to-volumes, execute-post-deployment-script]
    if: ${{ (inputs.environment != 'dev') }}
    steps:
      - name: Checkout main branch of DevSecOps repository
        uses: actions/checkout@v4
        with:
          repository: ${{ vars.DEVSECOPS_REPOSITORY_VAR }}
          ref: main
          fetch-depth: 0

      - name: Update a work item on Azure Boards
        uses: ./custom-actions/azure-devops-boards/update-work-item
        with:
          environment: ${{ inputs.environment }}
          work_item_id: ${{ needs.deploy-databricks-bundle.outputs.work_item_id }}
          board_column: '${{ inputs.environment }} Deployment'
          token: ${{ secrets.AZURE_DEVOPS_PAT }} #TODO ${{ secrets.AZURE_DEVOPS_TOKEN }}